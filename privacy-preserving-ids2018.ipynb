{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7892537,"sourceType":"datasetVersion","datasetId":4633977},{"sourceId":26100,"sourceType":"modelInstanceVersion","modelInstanceId":21972},{"sourceId":27707,"sourceType":"modelInstanceVersion","modelInstanceId":23344},{"sourceId":52543,"sourceType":"modelInstanceVersion","modelInstanceId":44137},{"sourceId":53062,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44549},{"sourceId":53112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44583},{"sourceId":53190,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44637}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries/Packages & Datasets","metadata":{"id":"vjoXjjOj2Kaq"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nimport time\nimport copy\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntorch.backends.cudnn.benchmark=True\nproc = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.manual_seed(5703)\ntorch.manual_seed(5703)\nnp.random.seed(5703)\nrandom.seed(5703)","metadata":{"id":"eMvQwUpC2CyT","execution":{"iopub.status.busy":"2024-05-26T09:37:39.901846Z","iopub.execute_input":"2024-05-26T09:37:39.902244Z","iopub.status.idle":"2024-05-26T09:37:45.649287Z","shell.execute_reply.started":"2024-05-26T09:37:39.902210Z","shell.execute_reply":"2024-05-26T09:37:45.648328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fulldata = pd.read_csv('/kaggle/input/ids-all-attacks/CICIDS_ALLATTACKS.csv')\nfulldata['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:37:52.642234Z","iopub.execute_input":"2024-05-26T09:37:52.642792Z","iopub.status.idle":"2024-05-26T09:40:46.268842Z","shell.execute_reply.started":"2024-05-26T09:37:52.642758Z","shell.execute_reply":"2024-05-26T09:40:46.267794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with 'Benign' and 'Infilteration' labels\nfulldata = fulldata[(fulldata['Label'] != 'Benign') & (fulldata['Label'] != 'Infilteration')]\n\n# Display the value counts of the labels after dropping\nprint(\"\\nAfter dropping:\")\nprint(fulldata['Label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:40:46.270706Z","iopub.execute_input":"2024-05-26T09:40:46.271016Z","iopub.status.idle":"2024-05-26T09:40:48.075774Z","shell.execute_reply.started":"2024-05-26T09:40:46.270991Z","shell.execute_reply":"2024-05-26T09:40:48.074754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datas = {}\nmixed_data = pd.DataFrame()\nold=[]\ntest_data = pd.DataFrame()\nfor i in fulldata['Label'].unique():\n    if fulldata[fulldata['Label'] == i].shape[0] > 100000:\n        print(i)\n        old.append(i)\n        train_datas[i] = fulldata[fulldata['Label'] == i][:100000]\n        mixed_data = pd.concat([mixed_data, fulldata[fulldata['Label'] == i][100000:110000]], axis=0)\n        test_data = pd.concat([test_data, fulldata[fulldata['Label'] == i][110000:120000]], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:41:38.399456Z","iopub.execute_input":"2024-05-26T09:41:38.399866Z","iopub.status.idle":"2024-05-26T09:41:45.344687Z","shell.execute_reply.started":"2024-05-26T09:41:38.399824Z","shell.execute_reply":"2024-05-26T09:41:45.343555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new=[\"DDOS attack-HOIC-1\",\"DDOS attack-HOIC-2\",\"Bot-1\",\"FTP-BruteForce-1\",\"SSH-Bruteforce-1\"]\ntrain_datas[\"DDOS attack-HOIC-1\"]=fulldata[fulldata['Label'] == \"DDOS attack-HOIC\"][120000:220000]\ntrain_datas[\"DDOS attack-HOIC-2\"]=fulldata[fulldata['Label'] == \"DDOS attack-HOIC\"][220000:320000]\ntrain_datas[\"Bot-1\"]=fulldata[fulldata['Label'] == \"Bot\"][120000:220000]\ntrain_datas[\"FTP-BruteForce-1\"]=fulldata[fulldata['Label'] == \"FTP-BruteForce\"][120000:]\ntrain_datas[\"SSH-Bruteforce-1\"]=fulldata[fulldata['Label'] == \"SSH-Bruteforce\"][120000:160000]\n\n\"\"\"mixed_data = pd.DataFrame()\nfor i in train_datas.keys():\n    if i[:-2] in fulldata['Label'].unique():\n        mixed_data = pd.concat([mixed_data, fulldata[fulldata['Label'] == i[:-2]][110000:120000]], axis=0)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:41:47.522051Z","iopub.execute_input":"2024-05-26T09:41:47.522853Z","iopub.status.idle":"2024-05-26T09:41:48.560259Z","shell.execute_reply.started":"2024-05-26T09:41:47.522818Z","shell.execute_reply":"2024-05-26T09:41:48.559106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del fulldata","metadata":{"execution":{"iopub.status.busy":"2024-05-20T09:59:43.718815Z","iopub.status.idle":"2024-05-20T09:59:43.719174Z","shell.execute_reply.started":"2024-05-20T09:59:43.719001Z","shell.execute_reply":"2024-05-20T09:59:43.719017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mixed_data = mixed_data.sample(frac=1).reset_index(drop=True)\nmixed_data_labels = list(mixed_data['Label'])\nmixed_data.drop(['Label'], axis=1, inplace=True)\nmixed_data = mixed_data.to_numpy()\n\ntest_data = test_data.sample(frac=1).reset_index(drop=True)\ntest_data_labels = list(test_data['Label'])\ntest_data.drop(['Label'], axis=1, inplace=True)\ntest_data = test_data.to_numpy()\n\n\nfor i in train_datas:\n    train_datas[i].drop(['Label'], axis=1, inplace=True)\n    #test_datas[i].drop(['Label'], axis=1, inplace=True)\n    train_datas[i] = train_datas[i].sample(frac=1).reset_index(drop=True)\n    #test_datas[i] = test_datas[i].sample(frac=1).reset_index(drop=True)\n    train_datas[i] = train_datas[i].to_numpy()\n    #test_datas[i] = test_datas[i].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:41:55.968047Z","iopub.execute_input":"2024-05-26T09:41:55.968771Z","iopub.status.idle":"2024-05-26T09:41:56.719505Z","shell.execute_reply.started":"2024-05-26T09:41:55.968736Z","shell.execute_reply":"2024-05-26T09:41:56.718607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading data into pytorch dataloader as train and test\ndevices = []\nbatch_size = 32\ntrain_loader = {}\nfor i in train_datas:\n    train_loader[i] = torch.utils.data.DataLoader(train_datas[i], batch_size = batch_size, shuffle=True)\n    devices.append(i)","metadata":{"id":"LCBO3J8zgdgJ","execution":{"iopub.status.busy":"2024-05-26T09:42:00.035009Z","iopub.execute_input":"2024-05-26T09:42:00.035916Z","iopub.status.idle":"2024-05-26T09:42:00.041678Z","shell.execute_reply.started":"2024-05-26T09:42:00.035882Z","shell.execute_reply":"2024-05-26T09:42:00.040297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:42:10.730200Z","iopub.execute_input":"2024-05-26T09:42:10.730598Z","iopub.status.idle":"2024-05-26T09:42:10.737840Z","shell.execute_reply.started":"2024-05-26T09:42:10.730566Z","shell.execute_reply":"2024-05-26T09:42:10.736610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for label in train_datas.keys():\n    print(len(train_datas[label]),train_datas[label].shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:42:18.813464Z","iopub.execute_input":"2024-05-26T09:42:18.813878Z","iopub.status.idle":"2024-05-26T09:42:18.819090Z","shell.execute_reply.started":"2024-05-26T09:42:18.813846Z","shell.execute_reply":"2024-05-26T09:42:18.818053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialising config variables\nnum_clients = len(train_loader)     \nnum_selected = len(train_loader)    \nnum_rounds = 1     \nepochs = 10        \n","metadata":{"id":"XAsJUgfC5IuY","execution":{"iopub.status.busy":"2024-05-25T06:41:31.239678Z","iopub.execute_input":"2024-05-25T06:41:31.240152Z","iopub.status.idle":"2024-05-25T06:41:31.246677Z","shell.execute_reply.started":"2024-05-25T06:41:31.240119Z","shell.execute_reply":"2024-05-25T06:41:31.245248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Auto-encoder Client Models (Training and Testing)","metadata":{"id":"sPE5Fx5I7HZM"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\n\ninput_dim = train_loader['Bot'].dataset.shape[1]\n\n# Define AEModel with regularization\nclass AEModel(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.fc8 = nn.Linear(16, 24)\n        self.fc9 = nn.Linear(24, 32)\n        self.fc10 = nn.Linear(32, 48)\n        self.fc11 = nn.Linear(48, 64)\n        self.fc12 = nn.Linear(64, input_dim)\n        self.fc13 = nn.Linear(input_dim, input_dim)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc8(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc9(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc10(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc11(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc12(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc13(x)\n        return x","metadata":{"id":"QkVroa1V5IjN","execution":{"iopub.status.busy":"2024-05-26T09:43:13.577493Z","iopub.execute_input":"2024-05-26T09:43:13.577944Z","iopub.status.idle":"2024-05-26T09:43:13.593164Z","shell.execute_reply.started":"2024-05-26T09:43:13.577912Z","shell.execute_reply":"2024-05-26T09:43:13.592017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for client update with regularization\ndef client_update(client_model, optimizer, train_data, epoch=3):\n    client_model.train()\n    criterion = nn.MSELoss(reduction='mean')\n    for e in range(epoch):\n        running_loss = 0.0\n        for data in train_data:\n            output = client_model(data.float())\n            optimizer.zero_grad()\n            loss = criterion(data.float().to(proc), output)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        epoch_loss = running_loss / len(train_data)\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:43:17.068945Z","iopub.execute_input":"2024-05-26T09:43:17.069335Z","iopub.status.idle":"2024-05-26T09:43:17.076305Z","shell.execute_reply.started":"2024-05-26T09:43:17.069302Z","shell.execute_reply":"2024-05-26T09:43:17.075197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client_models = {i: AEModel(input_dim).to(proc) for i in devices}\n#opt = {i: optim.SGD(client_models[i].parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5) for i in devices}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:46:30.591664Z","iopub.execute_input":"2024-05-21T09:46:30.592036Z","iopub.status.idle":"2024-05-21T09:46:33.590785Z","shell.execute_reply.started":"2024-05-21T09:46:30.592009Z","shell.execute_reply":"2024-05-21T09:46:33.589701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = {i: optim.Adam( client_models[i].parameters(), lr=0.0005,  weight_decay=1e-5) for i in devices}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:47:06.450174Z","iopub.execute_input":"2024-05-21T09:47:06.450581Z","iopub.status.idle":"2024-05-21T09:47:06.457908Z","shell.execute_reply.started":"2024-05-21T09:47:06.450552Z","shell.execute_reply":"2024-05-21T09:47:06.456510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Client Model and Global Model\nstart_time = time.time()\nfor r in range(num_rounds):  # total number of rounds\n    print('\\nround: ', r+1)\n    loss = 0\n    for i in devices:\n        l = client_update(client_models[i], opt[i], train_loader[i], epochs)\n        print('client: ', i, 'loss: ', l)\n        loss += l\ntime_required = time.time() - start_time\nprint('/nTIME: {}mins'.format(time_required/60))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T11:30:16.643817Z","iopub.execute_input":"2024-05-21T11:30:16.644206Z","iopub.status.idle":"2024-05-21T11:49:37.525978Z","shell.execute_reply.started":"2024-05-21T11:30:16.644170Z","shell.execute_reply":"2024-05-21T11:49:37.524017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntry:\n    os.makedirs('/kaggle/working/models_extra/clients/')\nexcept:\n    pass\nfor i in devices:\n    torch.save(client_models[i],'/kaggle/working/models_extra/clients/' + i + '.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T11:50:04.029055Z","iopub.execute_input":"2024-05-21T11:50:04.029888Z","iopub.status.idle":"2024-05-21T11:50:04.060950Z","shell.execute_reply.started":"2024-05-21T11:50:04.029854Z","shell.execute_reply":"2024-05-21T11:50:04.059556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client_models = {}\nfor device in old:\n    client_models[device] = torch.load('/kaggle/input/models_fixed_overfit/pytorch/extramodels_levi_50epoch/1/models_extra_Levi/clients_Levi/' + device + '.pt')\nclient_models.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T07:21:29.478952Z","iopub.execute_input":"2024-05-25T07:21:29.479455Z","iopub.status.idle":"2024-05-25T07:21:29.548126Z","shell.execute_reply.started":"2024-05-25T07:21:29.479421Z","shell.execute_reply":"2024-05-25T07:21:29.547167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def quan_thresh(model, dataloader, quantile=0.9):\n    model.eval()\n    se = []\n    for batch in dataloader:\n        for data in batch:\n            error = np.power(data.float().cpu().numpy() - model(data.float()).cpu().detach().numpy(), 2) # len(error) = 66\n            se.append(sum(error))\n    # Calculate threshold as quantile of errors \n    #thresh = np.quantile(se, quantile, axis=0) #before it was thresh = np.quantile(mse, quantile)\n    #errs.append(thresh)\n    #thresh = np.quantile(mse, quantile)\n    return np.mean(se) + np.std(se), np.quantile(se, quantile), se #before it was np.mean(errs)\n  #return thresh\n\ndef perf_measure(y_actual, y_pred):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    for i in range(len(y_pred)):\n        if y_actual[i] == y_pred[i] == 1:\n            TP += 1\n        if y_pred[i] == 1 and y_actual[i] != y_pred[i]:\n            FP += 1\n        if y_actual[i] == y_pred[i] == 0:\n            TN += 1\n        if y_pred[i] == 0 and y_actual[i] != y_pred[i]:\n            FN += 1\n    return (TP, FP, TN, FN)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T07:21:34.022228Z","iopub.execute_input":"2024-05-25T07:21:34.022971Z","iopub.status.idle":"2024-05-25T07:21:34.035396Z","shell.execute_reply.started":"2024-05-25T07:21:34.022919Z","shell.execute_reply":"2024-05-25T07:21:34.034075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds = {}\nquans = {}\nerrors = {}\nfor device in devices:\n    model = client_models[device]\n    model.eval()\n    dataloader = train_loader[device]\n    thresholds[device], quans[device], errors[device] = quan_thresh(model, dataloader)\n    #thresholds[devices[i]] = quan_recon(model, dataloader)\nprint(thresholds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import spearmanr, rankdata, pearsonr\nfrom sklearn.metrics import mutual_info_score\nselectedattackbenmix_stats = []\nres=[]\ndevice_idx = {device: i for i, device in enumerate(devices)}\nfor device in devices:\n    model = client_models[device]\n    model.eval()\n    labels = mixed_data_labels\n    threshold = thresholds[device]\n    temp=[]\n    y_true = []\n    y_pred = []\n    ind = 0\n    for data in mixed_data:\n        data = torch.Tensor(data)\n        error = np.sum(np.power(data.detach().numpy() - model(data).detach().numpy(), 2))\n        temp.append(error)\n        if device == labels[ind]:\n            y_true.append(1)\n            y_pred.append(1 if error < threshold else 0)\n        else:\n            y_true.append(0)\n            y_pred.append(0 if error >= threshold else 1)\n        ind += 1\n    res.append([device,min(temp),max(temp)])\n    TP, FP, TN, FN = perf_measure(y_true, y_pred)\n    TP += 1\n    FN += 1\n    TN += 1\n    FP += 1\n    conf_matrix = [[TP, FN], [FP, TN]]\n    plt.figure() \n    sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n    plt.title(\"Confusion Matrix for Client \" + str(device) +\" with mixed data\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n\n    acc = (TP+TN) / (TP+TN+FP+FN)\n    precision = TP/(TP+FP)\n    recall = TP/(TP+FN)\n    F1score = 2 * ((precision * recall) / (precision + recall))\n    TPR = round((TP / (TP+FN)), 6)\n    FPR = round((FP / (FP + TN)), 6)\n    selectedattackbenmix_stats.append([str(\"Stats for Client \" + str(device) +\" with mixed data\"),acc*100,precision,recall,F1score*100,TPR,FPR])\n\n  #   [['TP', 'FN']\n  #   ['FP', 'TN']]","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:39:41.088191Z","iopub.execute_input":"2024-05-21T15:39:41.088710Z","iopub.status.idle":"2024-05-21T15:45:57.967657Z","shell.execute_reply.started":"2024-05-21T15:39:41.088664Z","shell.execute_reply":"2024-05-21T15:45:57.966509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in selectedattackbenmix_stats:\n    print(\"Title: \" + i[0])\n    print(\"Accuracy: \" + str(i[1]))\n    print(\"Precision: \" + str(i[2]))\n    print(\"Recall: \" + str(i[3]))\n    print(\"F1 score : \" + str(i[4]))\n    print(\"TPR : \" + str(i[5]))\n    print(\"FPR : \" + str(i[6]))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:48:17.996330Z","iopub.execute_input":"2024-05-21T15:48:17.996824Z","iopub.status.idle":"2024-05-21T15:48:18.005883Z","shell.execute_reply.started":"2024-05-21T15:48:17.996790Z","shell.execute_reply":"2024-05-21T15:48:18.004527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\n\ninput_dim = train_loader['Bot'].dataset.shape[1]\n\n# Define AEModel with regularization\nclass AEModel(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.fc8 = nn.Linear(16, 24)\n        self.fc9 = nn.Linear(24, 32)\n        self.fc10 = nn.Linear(32, 48)\n        self.fc11 = nn.Linear(48, 64)\n        self.fc12 = nn.Linear(64, input_dim)\n        self.fc13 = nn.Linear(input_dim, input_dim)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc8(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc9(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc10(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc11(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc12(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc13(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:56:02.144189Z","iopub.execute_input":"2024-05-22T12:56:02.144711Z","iopub.status.idle":"2024-05-22T12:56:02.218384Z","shell.execute_reply.started":"2024-05-22T12:56:02.144666Z","shell.execute_reply":"2024-05-22T12:56:02.216835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client_models = {}\nfor device in devices:\n    client_models[device] = torch.load('/kaggle/input/models_fixed_overfit/pytorch/extramodels_levi_50epoch/1/models_extra_Levi/clients_Levi/' + device + '.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:42:40.085373Z","iopub.execute_input":"2024-05-21T14:42:40.085818Z","iopub.status.idle":"2024-05-21T14:42:40.133998Z","shell.execute_reply.started":"2024-05-21T14:42:40.085785Z","shell.execute_reply":"2024-05-21T14:42:40.132672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the encoder-only model class\nclass AEModelEncoder(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModelEncoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        \n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        return x\n\n# Function to load encoder weights from the full model\ndef load_encoder_weights(full_model, encoder_model):\n    encoder_model.fc1.weight.data = full_model.fc1.weight.data\n    encoder_model.fc1.bias.data = full_model.fc1.bias.data\n    encoder_model.fc2.weight.data = full_model.fc2.weight.data\n    encoder_model.fc2.bias.data = full_model.fc2.bias.data\n    encoder_model.fc3.weight.data = full_model.fc3.weight.data\n    encoder_model.fc3.bias.data = full_model.fc3.bias.data\n    encoder_model.fc4.weight.data = full_model.fc4.weight.data\n    encoder_model.fc4.bias.data = full_model.fc4.bias.data\n    encoder_model.fc5.weight.data = full_model.fc5.weight.data\n    encoder_model.fc5.bias.data = full_model.fc5.bias.data\n    encoder_model.fc6.weight.data = full_model.fc6.weight.data\n    encoder_model.fc6.bias.data = full_model.fc6.bias.data\n    encoder_model.fc7.weight.data = full_model.fc7.weight.data\n    encoder_model.fc7.bias.data = full_model.fc7.bias.data\n\n# Update client_models to use the encoder-only model\nclient_models_encoders = {}\nfor device in devices:\n    full_model = torch.load('/kaggle/input/models_fixed_overfit/pytorch/extramodels_levi_50epoch/1/models_extra_Levi/clients_Levi/' + device + '.pt')\n    encoder_model = AEModelEncoder(input_dim)\n    load_encoder_weights(full_model, encoder_model)\n    client_models_encoders[device] = encoder_model","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:42:41.070951Z","iopub.execute_input":"2024-05-21T14:42:41.071381Z","iopub.status.idle":"2024-05-21T14:42:41.145696Z","shell.execute_reply.started":"2024-05-21T14:42:41.071344Z","shell.execute_reply":"2024-05-21T14:42:41.144355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agg_models={}\nclient_lens={}\nagg_models_labels={}\nfor i in client_models_encoders.keys():\n    if i[:-2] in client_models_encoders.keys():\n        try:\n            agg_models[i[:-2]].append(client_models_encoders[i])\n            agg_models_labels[i[:-2]].append(i)\n            client_lens[i[:-2]].append(len(train_datas[i]))\n            print(i)\n        except:\n            print(i)\n            agg_models[i[:-2]]=[client_models_encoders[i[:-2]],client_models_encoders[i]]\n            agg_models_labels[i[:-2]]=[i[:-2],i]\n            client_lens[i[:-2]]=[len(train_datas[i[:-2]]),len(train_datas[i])]\n            ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:42:42.735829Z","iopub.execute_input":"2024-05-21T14:42:42.736284Z","iopub.status.idle":"2024-05-21T14:42:42.747328Z","shell.execute_reply.started":"2024-05-21T14:42:42.736246Z","shell.execute_reply":"2024-05-21T14:42:42.746078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aggregates the model weights received from every client\n# and updates the global model with updated weights\n# FedAvg\ndef server_aggregate(global_model, client_models, client_lens):\n    total = sum(client_lens)\n    n = len(client_models)\n    # n = num_selected\n    global_dict = global_model.state_dict()\n    for k in global_dict.keys(): # calculate average weight/bias --> avg_w/b\n        global_dict[k] -= torch.stack([client_models[i].state_dict()[k].float() * (n * client_lens[i] / total) for i in range(len(client_models))], 0).mean(0)\n    global_model.load_state_dict(global_dict)\n    for model in client_models:\n        model.load_state_dict(global_model.state_dict()) # local model get updated weight/bias\n        \n# FedAvgM\ndef server_aggregate_M(global_model, client_models, client_lens):\n    total = sum(client_lens)    # 592    sum [51, 122, 162, 257]\n    n = len(client_models)      # 4 local clients\n    global_dict = global_model.state_dict() # weight/bias dict --> {'encoder.0.weight': Tensor with shape torch.Size([86, 115]), 'encoder.0.bias':....} 16 items\n    temp = copy.deepcopy(global_dict)       # temporary weight/bias dict\n    v = {x:1 for x in copy.deepcopy(global_dict)}   # initialise v\n\n    for i,k in enumerate(global_dict.keys()):\n        # calculate average weight/bias --> avg_w/b\n        temp[k] = torch.stack([client_models[i].state_dict()[k].float() * (n * client_lens[i] / total) for i in range(len(client_models))], 0).mean(0)\n        temp_v = 0.9 * v[k] + temp[k]               # v = 0.9v + avg_w/b   momentum=0.9\n        global_dict[k] = global_dict[k] - temp_v    # w = w - v\n    global_model.load_state_dict(global_dict)\n\n    for model in client_models:\n        model.load_state_dict(global_model.state_dict()) # local model get updated weight/bias\n\n\ndef server_aggregate_fedprox(global_model, client_models, mu=0.05):\n    n = len(client_models)\n    global_dict = global_model.state_dict()\n    \n    for k in global_dict.keys():\n        # Calculate the average of the client model parameters\n        global_weight = sum(client_models[i].state_dict()[k].float() for i in range(n)) / n\n        \n        # Apply the FedProx proximal term\n        prox_term = mu * global_dict[k]\n        global_dict[k] = (global_weight + prox_term) / (1 + mu)\n    \n    # Load the updated parameters into the global model\n    global_model.load_state_dict(global_dict)\n    \n    # Update each client model with the new global parameters\n    for model in client_models:\n        model.load_state_dict(global_model.state_dict())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:42:44.962224Z","iopub.execute_input":"2024-05-21T14:42:44.963310Z","iopub.status.idle":"2024-05-21T14:42:44.977721Z","shell.execute_reply.started":"2024-05-21T14:42:44.963261Z","shell.execute_reply":"2024-05-21T14:42:44.976512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"epochs=1\ntrained=[]\nfor r in range(2):\n    print('\\n Round: ', r+1)\n    for i in agg_models.keys():\n        server_aggregate_M(client_models_encoders[i],agg_models[i],client_lens[i])\n        for j in client_models.keys():\n            if j[:-2] in client_models.keys():\n                load_encoder_weights(client_models_encoders[i],client_models[j])\n                if j[:-2] not in trained:\n                    load_encoder_weights(client_models_encoders[i],client_models[j[:-2]])\n                    loss = 0\n                    l = client_update(client_models[j[:-2]], opt[j[:-2]], train_loader[j[:-2]], epochs)\n                    print('client: ', j[:-2], 'loss: ', l)\n                    loss += l\n                    trained.append(j[:-2])\n                loss = 0\n                l = client_update(client_models[j], opt[j], train_loader[j], epochs)\n                print('client: ', j, 'loss: ', l)\n                loss += l\n        trained=[]\n        for k in agg_models[i]:\n            for j in client_models.keys():\n                if agg_models_labels[i][agg_models[i].index(k)] == j:\n                    load_encoder_weights(client_models[j],k)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-20T20:39:09.617201Z","iopub.execute_input":"2024-05-20T20:39:09.618316Z","iopub.status.idle":"2024-05-20T20:39:09.628311Z","shell.execute_reply.started":"2024-05-20T20:39:09.618264Z","shell.execute_reply":"2024-05-20T20:39:09.626845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"epochs=2\ntrained=[]\nfor r in range(5):\n    print('\\nround: ', r+1)\n    for i in agg_models.keys():\n        server_aggregate_fedprox(client_models_encoders[i],agg_models[i])\n        for k in agg_models[i]:\n            for j in client_models_encoders.keys():\n                if agg_models_labels[i][agg_models[i].index(k)] == j:\n                    load_encoder_weights(client_models_encoders[j],client_models[j])\n    for j in client_models.keys():\n        if j[:-2] in client_models.keys():\n            if j[:-2] not in trained:\n                for name, param in client_models[j].named_parameters():\n                    if 'fc7' in name or 'fc8' in name or 'fc9' in name or 'fc10' in name or 'fc11' in name or 'fc12' in name or 'fc13' in name:\n                        param.requires_grad = False\n                loss = 0\n                l = client_update(client_models[j[:-2]], opt[j[:-2]], train_loader[j[:-2]], epochs)\n                print('client: ', j[:-2], 'loss: ', l)\n                loss += l\n                trained.append(j[:-2])\n            loss = 0\n            for name, param in client_models[j].named_parameters():\n                if 'fc7' in name or 'fc8' in name or 'fc9' in name or 'fc10' in name or 'fc11' in name or 'fc12' in name or 'fc13' in name:\n                    param.requires_grad = False\n            l = client_update(client_models[j], opt[j], train_loader[j], epochs)\n            print('client: ', j, 'loss: ', l)\n            loss += l\n    trained=[]\n    for i in agg_models.keys():\n        for k in agg_models[i]:\n            for j in client_models.keys():\n                if agg_models_labels[i][agg_models[i].index(k)] == j:\n                    load_encoder_weights(client_models[j],k)\n        \n\nfor i in agg_models.keys():\n    server_aggregate_fedprox(client_models_encoders[i],agg_models[i])\n    for k in agg_models[i]:\n        for j in client_models_encoders.keys():\n            if agg_models_labels[i][agg_models[i].index(k)] == j:\n                load_encoder_weights(client_models_encoders[j],client_models[j])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-20T20:39:10.148998Z","iopub.execute_input":"2024-05-20T20:39:10.149414Z","iopub.status.idle":"2024-05-20T20:39:10.160617Z","shell.execute_reply.started":"2024-05-20T20:39:10.149370Z","shell.execute_reply":"2024-05-20T20:39:10.159332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#opt = {i: optim.Adam( client_models[i].parameters(), lr=0.0005,  weight_decay=1e-5) for i in devices}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T11:56:51.733938Z","iopub.execute_input":"2024-05-21T11:56:51.734375Z","iopub.status.idle":"2024-05-21T11:56:51.746508Z","shell.execute_reply.started":"2024-05-21T11:56:51.734341Z","shell.execute_reply":"2024-05-21T11:56:51.745237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = {i: optim.SGD(client_models[i].parameters(), lr=0.0005, momentum=0.9, weight_decay=1e-5) for i in devices}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:43:03.451243Z","iopub.execute_input":"2024-05-21T14:43:03.451642Z","iopub.status.idle":"2024-05-21T14:43:03.465569Z","shell.execute_reply.started":"2024-05-21T14:43:03.451615Z","shell.execute_reply":"2024-05-21T14:43:03.464385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=2\ntrained=[]\nfor r in range(5):\n    print('\\nround: ', r+1)\n    for i in agg_models.keys():\n        server_aggregate_fedprox(client_models_encoders[i],agg_models[i])\n        for k in agg_models[i]:\n            for j in client_models_encoders.keys():\n                if agg_models_labels[i][agg_models[i].index(k)] == j:\n                    load_encoder_weights(client_models_encoders[j],client_models[j])\n    for j in client_models.keys():\n        if j[:-2] in client_models.keys():\n            if j[:-2] not in trained:\n                loss = 0\n                l = client_update(client_models[j[:-2]], opt[j[:-2]], train_loader[j[:-2]], epochs)\n                print('client: ', j[:-2], 'loss: ', l)\n                loss += l\n                trained.append(j[:-2])\n            loss = 0\n            l = client_update(client_models[j], opt[j], train_loader[j], epochs)\n            print('client: ', j, 'loss: ', l)\n            loss += l\n    trained=[]\n    for i in agg_models.keys():\n        for k in agg_models[i]:\n            for j in client_models.keys():\n                if agg_models_labels[i][agg_models[i].index(k)] == j:\n                    load_encoder_weights(client_models[j],k)\n        \n\nfor i in agg_models.keys():\n    server_aggregate_fedprox(client_models_encoders[i],agg_models[i])\n    for k in agg_models[i]:\n        for j in client_models_encoders.keys():\n            if agg_models_labels[i][agg_models[i].index(k)] == j:\n                load_encoder_weights(client_models_encoders[j],client_models[j])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:06:58.758869Z","iopub.execute_input":"2024-05-21T15:06:58.759286Z","iopub.status.idle":"2024-05-21T15:24:54.240531Z","shell.execute_reply.started":"2024-05-21T15:06:58.759251Z","shell.execute_reply":"2024-05-21T15:24:54.239247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntry:\n    os.makedirs('/kaggle/working/models_extra/clients/')\nexcept:\n    pass\nfor i in devices:\n    torch.save(client_models[i],'/kaggle/working/models_extra/clients/' + i + '.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:26:18.456705Z","iopub.execute_input":"2024-05-21T15:26:18.457369Z","iopub.status.idle":"2024-05-21T15:26:18.510229Z","shell.execute_reply.started":"2024-05-21T15:26:18.457320Z","shell.execute_reply":"2024-05-21T15:26:18.508870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global model creation (K-means)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\n\ninput_dim = train_loader['Bot'].dataset.shape[1]\n\n# Define AEModel with regularization\nclass AEModel(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.fc8 = nn.Linear(16, 24)\n        self.fc9 = nn.Linear(24, 32)\n        self.fc10 = nn.Linear(32, 48)\n        self.fc11 = nn.Linear(48, 64)\n        self.fc12 = nn.Linear(64, input_dim)\n        self.fc13 = nn.Linear(input_dim, input_dim)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc8(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc9(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc10(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc11(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc12(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc13(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:11:59.630775Z","iopub.execute_input":"2024-05-26T10:11:59.631295Z","iopub.status.idle":"2024-05-26T10:11:59.647186Z","shell.execute_reply.started":"2024-05-26T10:11:59.631260Z","shell.execute_reply":"2024-05-26T10:11:59.645850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"client_models = {}\nfor device in devices:\n    client_models[device] = torch.load('/kaggle/input/models_fixed_overfit/pytorch/extramodels/1/' + device + '.pt')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:11:59.828833Z","iopub.execute_input":"2024-05-26T10:11:59.829234Z","iopub.status.idle":"2024-05-26T10:11:59.835897Z","shell.execute_reply.started":"2024-05-26T10:11:59.829201Z","shell.execute_reply":"2024-05-26T10:11:59.834841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the encoder-only model class\nclass AEModelEncoder(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModelEncoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        \n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        return x\n\n# Function to load encoder weights from the full model\ndef load_encoder_weights(full_model, encoder_model):\n    encoder_model.fc1.weight.data = full_model.fc1.weight.data\n    encoder_model.fc1.bias.data = full_model.fc1.bias.data\n    encoder_model.fc2.weight.data = full_model.fc2.weight.data\n    encoder_model.fc2.bias.data = full_model.fc2.bias.data\n    encoder_model.fc3.weight.data = full_model.fc3.weight.data\n    encoder_model.fc3.bias.data = full_model.fc3.bias.data\n    encoder_model.fc4.weight.data = full_model.fc4.weight.data\n    encoder_model.fc4.bias.data = full_model.fc4.bias.data\n    encoder_model.fc5.weight.data = full_model.fc5.weight.data\n    encoder_model.fc5.bias.data = full_model.fc5.bias.data\n    encoder_model.fc6.weight.data = full_model.fc6.weight.data\n    encoder_model.fc6.bias.data = full_model.fc6.bias.data\n    encoder_model.fc7.weight.data = full_model.fc7.weight.data\n    encoder_model.fc7.bias.data = full_model.fc7.bias.data\n\n# Update client_models to use the encoder-only model\nclient_models = {}\nfor device in old:\n    full_model = torch.load('/kaggle/input/models_fixed_overfit/pytorch/extramodels_levi_50epoch/1/models_extra_Levi/clients_Levi/' + device + '.pt')\n    encoder_model = AEModelEncoder(input_dim)\n    load_encoder_weights(full_model, encoder_model)\n    client_models[device] = encoder_model\nclient_models.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:22:31.931964Z","iopub.execute_input":"2024-05-26T11:22:31.932397Z","iopub.status.idle":"2024-05-26T11:22:32.007053Z","shell.execute_reply.started":"2024-05-26T11:22:31.932346Z","shell.execute_reply":"2024-05-26T11:22:32.005875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_outs = {}\ncompressed_outs_test = {}\nfor i in client_models:\n    model = client_models[i]\n    model.eval()\n    dataloader = train_loader[i]\n    outs = []\n    ind = 0\n    flag = False\n    for batch in dataloader:\n        for data in batch:\n            layer_output = model(data.float()).detach().numpy()\n            outs.append(layer_output)\n            ind += 1\n            if ind == 20000:\n                compressed_outs[i] = outs\n                outs = []\n            elif ind == 20010:\n                compressed_outs_test[i] = outs\n                flag = True\n                break\n        if flag:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:12:00.397539Z","iopub.execute_input":"2024-05-26T10:12:00.397937Z","iopub.status.idle":"2024-05-26T10:12:47.198076Z","shell.execute_reply.started":"2024-05-26T10:12:00.397908Z","shell.execute_reply":"2024-05-26T10:12:47.196594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in compressed_outs:\n    if i[:-2] in compressed_outs:\n        for j in compressed_outs[i]:\n            compressed_outs[i[:-2]].append(j)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:12:47.200067Z","iopub.execute_input":"2024-05-26T10:12:47.200437Z","iopub.status.idle":"2024-05-26T10:12:47.205986Z","shell.execute_reply.started":"2024-05-26T10:12:47.200407Z","shell.execute_reply":"2024-05-26T10:12:47.204912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[]\nfor i in compressed_outs:\n    if i[-2]==\"-\":\n        l.append(i)\nfor i in l:\n    compressed_outs.pop(i)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:12:47.207317Z","iopub.execute_input":"2024-05-26T10:12:47.207734Z","iopub.status.idle":"2024-05-26T10:12:47.217523Z","shell.execute_reply.started":"2024-05-26T10:12:47.207705Z","shell.execute_reply":"2024-05-26T10:12:47.216417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in compressed_outs.keys():\n    print(i,': ',len(compressed_outs[i]))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:12:47.219761Z","iopub.execute_input":"2024-05-26T10:12:47.220145Z","iopub.status.idle":"2024-05-26T10:12:47.229487Z","shell.execute_reply.started":"2024-05-26T10:12:47.220107Z","shell.execute_reply":"2024-05-26T10:12:47.228338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import random\n\n# Function to shuffle and reduce the number of samples for each label\ndef shuffle_and_reduce(data_dict, num_samples=10000):\n    reduced_data_dict = {}\n    for label, data in data_dict.items():\n        # Shuffle the data\n        random.shuffle(data)\n        # Store only the specified number of samples\n        reduced_data_dict[label] = data[:num_samples]\n    return reduced_data_dict\n# Apply the shuffle and reduce function\ncompressed_outs_reduced = shuffle_and_reduce(compressed_outs, num_samples=10000)\n\n# Print the results to verify\nfor label, data in compressed_outs_reduced.items():\n    print(f\"{label} : {len(data)}\")\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T11:50:54.128738Z","iopub.execute_input":"2024-05-25T11:50:54.129174Z","iopub.status.idle":"2024-05-25T11:50:54.138783Z","shell.execute_reply.started":"2024-05-25T11:50:54.129140Z","shell.execute_reply":"2024-05-25T11:50:54.137131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n# Extract data from the dictionary\ndata = []\nlabels = []\n\nfor label, tensors in compressed_outs.items():\n    for tensor in tensors:\n        data.append(tensor)\n        labels.append(label)\n\ndata = np.array(data)\nlabels = np.array(labels)\n\n# Get the number of samples\nnum_samples = len(data)\n\n# Generate a random permutation of indices\npermutation_indices = np.random.permutation(num_samples)\n\n# Shuffle data and labels arrays using the permutation\nshuffled_data = data[permutation_indices]\nshuffled_labels = labels[permutation_indices]\ndata=shuffled_data\nlabels=shuffled_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:12:47.230972Z","iopub.execute_input":"2024-05-26T10:12:47.231429Z","iopub.status.idle":"2024-05-26T10:12:47.665336Z","shell.execute_reply.started":"2024-05-26T10:12:47.231393Z","shell.execute_reply":"2024-05-26T10:12:47.664211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from joblib import load\n\nkmeans = load('//kaggle/input/models_fixed_overfit/other/kmeans/1/kmeans_model.joblib')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T11:50:54.482740Z","iopub.execute_input":"2024-05-25T11:50:54.483727Z","iopub.status.idle":"2024-05-25T11:50:54.492460Z","shell.execute_reply.started":"2024-05-25T11:50:54.483689Z","shell.execute_reply":"2024-05-25T11:50:54.491135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=22\n# Apply KMeans clustering\nkmeans = KMeans(n_clusters=n,random_state=100)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:35:19.074688Z","iopub.execute_input":"2024-05-26T10:35:19.075276Z","iopub.status.idle":"2024-05-26T10:35:19.081760Z","shell.execute_reply.started":"2024-05-26T10:35:19.075242Z","shell.execute_reply":"2024-05-26T10:35:19.080450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels = kmeans.fit_predict(data)\n\n# Get the cluster centroids\ncentroids = kmeans.cluster_centers_\n\n# Create a larger figure\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Visualize the clusters with different colors for each label\nscatter = ax.scatter(data[:, 0], data[:, 1], c=cluster_labels, cmap='Set1', alpha=0.5)\n\n# Plot the centroids\nax.scatter(centroids[:, 0], centroids[:, 1], c='yellowgreen', s=200, alpha=0.5)\n\n# Add legend with label names only if there are valid elements\nif scatter.legend_elements()[0] is not None and len(scatter.legend_elements()[0]) > 0:\n    unique_labels = list(set(labels))\n    legend_labels = [f'{label} ({i})' for i, label in enumerate(unique_labels)]\n    ax.legend(handles=scatter.legend_elements()[0], labels=legend_labels, title='Labels')\n\nax.set_title('KMeans Clustering')\nax.set_xlabel('Feature 1')\nax.set_ylabel('Feature 2')\n\nplt.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:35:20.404974Z","iopub.execute_input":"2024-05-26T10:35:20.405413Z","iopub.status.idle":"2024-05-26T10:35:29.705962Z","shell.execute_reply.started":"2024-05-26T10:35:20.405376Z","shell.execute_reply":"2024-05-26T10:35:29.704626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary to store attacks and their counts for each cluster\ncluster_attacks_count = {cluster: {} for cluster in range(n)}\n\n# Iterate through data and cluster labels\nfor idx, cluster_label in enumerate(cluster_labels):\n    attack = labels[idx]\n    if attack not in cluster_attacks_count[cluster_label]:\n        cluster_attacks_count[cluster_label][attack] = 1\n        \n    else:\n        cluster_attacks_count[cluster_label][attack] += 1\n    \n# Print attacks and their counts for each cluster\nfor cluster, attack_counts in cluster_attacks_count.items():\n    print(f\"Cluster {cluster}: {attack_counts}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:35:29.707821Z","iopub.execute_input":"2024-05-26T10:35:29.708147Z","iopub.status.idle":"2024-05-26T10:35:30.300069Z","shell.execute_reply.started":"2024-05-26T10:35:29.708121Z","shell.execute_reply":"2024-05-26T10:35:30.298822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels = {}\nfor i in range(n):\n    cluster_labels[i] = max(cluster_attacks_count[i], key=cluster_attacks_count[i].get)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:35:30.301448Z","iopub.execute_input":"2024-05-26T10:35:30.301805Z","iopub.status.idle":"2024-05-26T10:35:30.307309Z","shell.execute_reply.started":"2024-05-26T10:35:30.301775Z","shell.execute_reply":"2024-05-26T10:35:30.306198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels={0: 'Bot',\n 1: 'DDOS attack-HOIC',\n 2: 'FTP-BruteForce',\n 3: 'DoS attacks-Hulk',\n 4: 'DoS attacks-SlowHTTPTest',\n 5: 'DDoS attacks-LOIC-HTTP',\n 6: 'DDoS attacks-LOIC-HTTP',\n 7: 'SSH-Bruteforce',\n 8: 'DDOS attack-HOIC',\n 9: 'SSH-Bruteforce',\n 10: 'Bot',\n 11: 'DoS attacks-Hulk',\n 12: 'FTP-BruteForce',\n 13: 'DoS attacks-SlowHTTPTest',\n 14: 'DoS attacks-Hulk',\n 15: 'FTP-BruteForce',\n 16: 'DoS attacks-SlowHTTPTest',\n 17: 'FTP-BruteForce',\n 18: 'DoS attacks-SlowHTTPTest',\n 19: 'DDoS attacks-LOIC-HTTP',\n 20: 'DoS attacks-SlowHTTPTest',\n 21: 'DDoS attacks-LOIC-HTTP'}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:22:38.799663Z","iopub.execute_input":"2024-05-26T11:22:38.800078Z","iopub.status.idle":"2024-05-26T11:22:38.806743Z","shell.execute_reply.started":"2024-05-26T11:22:38.800044Z","shell.execute_reply":"2024-05-26T11:22:38.805329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[]\nfor i in client_models.keys():\n    if i[-2]==\"-\":\n        l.append(i)\nfor i in l:\n    client_models.pop(i)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:22:40.434293Z","iopub.execute_input":"2024-05-26T11:22:40.434698Z","iopub.status.idle":"2024-05-26T11:22:40.440761Z","shell.execute_reply.started":"2024-05-26T11:22:40.434669Z","shell.execute_reply":"2024-05-26T11:22:40.439568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_mixed = {}\nj=0\nfor data in mixed_data:\n    if j<1000:\n        for i in client_models:\n            model = client_models[i]\n            model.eval()\n            layer_output = model(torch.Tensor(data))\n            try:\n                compressed_mixed[i].append(layer_output)\n            except:\n                compressed_mixed[i] = [layer_output]\n    j+=1","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:32:30.794097Z","iopub.execute_input":"2024-05-26T11:32:30.794564Z","iopub.status.idle":"2024-05-26T11:32:34.490149Z","shell.execute_reply.started":"2024-05-26T11:32:30.794526Z","shell.execute_reply":"2024-05-26T11:32:34.489139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"#working\nn=27\nthreshold = 0.016\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T10:15:54.300614Z","iopub.execute_input":"2024-05-25T10:15:54.301007Z","iopub.status.idle":"2024-05-25T10:15:54.308972Z","shell.execute_reply.started":"2024-05-25T10:15:54.300975Z","shell.execute_reply":"2024-05-25T10:15:54.307723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_thresholds={'Bot': 0.31418854651204847,\n 'DDOS attack-HOIC': 0.03866640203996175,\n 'DDoS attacks-LOIC-HTTP': 0.46889474594200486,\n 'DoS attacks-Hulk': 0.48591240802465874,\n 'DoS attacks-SlowHTTPTest': 0.1051760870436359,\n 'FTP-BruteForce': 0.04449623069596497,\n 'SSH-Bruteforce': 0.07784218174722095}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:32:34.493695Z","iopub.execute_input":"2024-05-26T11:32:34.494032Z","iopub.status.idle":"2024-05-26T11:32:34.501408Z","shell.execute_reply.started":"2024-05-26T11:32:34.494005Z","shell.execute_reply":"2024-05-26T11:32:34.499972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_new_data(new_data_point, threshold):\n    # Predict the cluster for the new data point\n    new_data_cluster = kmeans.predict(np.array(new_data_point))\n    # Get the centroid of the predicted cluster\n    centroid = kmeans.cluster_centers_[new_data_cluster]\n    # Calculate the Euclidean distance between the new data point and the centroid\n    distance = np.sqrt(np.sum((new_data_point - centroid) ** 2))\n    # Classify based on the distance\n    if distance < threshold:\n        return new_data_cluster[0]\n    else:\n        return False\n\nnum_encoders=7\nnum_clusters=22\nnum_clients=7\nmet=[]\nstart = 0\nend =  min(old_thresholds.values())*num_encoders\nstep = end/num_clusters\ni = start\nfirst_round=[]\nprev_TPR=0\n\nfor x in range(num_clients):\n    met=[]\n    print(\"Round :\"+str(x+1))\n    while i < end:\n        TP,FP,TN,FN = 0,0,0,0\n        # Iterate through the compressed_mixed dictionary and classify each data point\n        for model, data_list in compressed_mixed.items():\n            j = 0\n            for data in data_list:\n                # Convert the data to NumPy array and detach from computation graph\n                data_np = data.detach().numpy()\n                data_np = data_np.reshape(1,-1)\n                # Convert the data to double data type before passing it to KMeans model\n                if classify_new_data(data_np, i) == False:\n                    classification_result = False\n                else: \n                    classification_result = cluster_labels[classify_new_data(data_np, i)]\n                if classification_result == False:\n                    if model == mixed_data_labels[j]:\n                        FN += 1\n                    else:\n                        TN += 1\n                else:\n                    if classification_result == mixed_data_labels[j]:\n                        if model == mixed_data_labels[j]:\n                            TP += 1\n                        else:\n                            FP += 1\n                    else:\n                        FN += 1\n                j += 1\n\n        if TP==0:\n            TP=0.1\n        # Calculate accuracy\n        accuracy = (TP + TN) / (TP + TN + FP + FN)\n\n        # Calculate true positive rate (TPR) or sensitivity or recall\n        TPR = TP / (TP + FN)\n\n        # Calculate false positive rate (FPR)\n        FPR = FP / (FP + TN)\n\n        # Calculate specificity or true negative rate (TNR)\n        TNR = TN / (FP + TN)\n\n        # Calculate precision or positive predictive value (PPV)\n        PPV = TP / (TP + FP)\n\n        met.append([i,accuracy,TPR,FPR,TNR])\n        if x==0:\n            first_round.append([i,accuracy,TPR,FPR,TNR])\n        i += step\n    print(met)\n    # Extracting data from 'fed_met' list\n    thresholds = [entry[0] for entry in met]\n    TPR = [entry[2] for entry in met]\n\n    # Find the best thresholds\n    # best_accuracy_idx = np.argmax(accuracy)\n\n    best_tpr_idx = np.argmax(TPR)\n    best_TPR = round(TPR[best_tpr_idx], 4)\n    if best_tpr_idx==0:\n        start=thresholds[best_tpr_idx]\n    else:\n        start=thresholds[best_tpr_idx-1]\n    if best_tpr_idx == len(thresholds) - 1:\n        end = thresholds[best_tpr_idx]\n    else:\n        end = thresholds[best_tpr_idx + 1]\n    step = end/num_clusters\n    i=start\n    if prev_TPR==best_TPR:\n        break\n    prev_TPR=best_TPR\n    #nxt_acc_thresh = threshold\n    #nxt_acc_thresh = thresholds[best_accuracy_idx+1]\n    #nxt_tpr_thresh = thresholds[best_tpr_idx+1]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:32:35.961737Z","iopub.execute_input":"2024-05-26T11:32:35.962119Z","iopub.status.idle":"2024-05-26T11:33:49.281541Z","shell.execute_reply.started":"2024-05-26T11:32:35.962090Z","shell.execute_reply":"2024-05-26T11:33:49.280177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting data from 'fed_met' list\nthresholds = [entry[0] for entry in met]\naccuracy = [entry[1] for entry in met]\nTPR = [entry[2] for entry in met]\nFPR = [entry[3] for entry in met]\nTNR = [entry[4] for entry in met]\n\n# Find the best thresholds\nbest_accuracy_idx = np.argmax(accuracy)\nbest_tpr_idx = np.argmax(TPR)\nbest_fpr_idx = np.argmin(FPR)\n\nbest_accuracy_threshold = thresholds[best_accuracy_idx]\nbest_tpr_threshold = thresholds[best_tpr_idx]\nbest_fpr_threshold = thresholds[best_fpr_idx]\n\nbest_tpr_threshold","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:34:28.482643Z","iopub.execute_input":"2024-05-26T11:34:28.483054Z","iopub.status.idle":"2024-05-26T11:34:28.494694Z","shell.execute_reply.started":"2024-05-26T11:34:28.483022Z","shell.execute_reply":"2024-05-26T11:34:28.493564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting data from 'fed_met' list\nthresholds = [entry[0] for entry in first_round]\naccuracy = [entry[1] for entry in first_round]\nTPR = [entry[2] for entry in first_round]\nFPR = [entry[3] for entry in first_round]\nTNR = [entry[4] for entry in first_round]\n\n# Find the best thresholds\nbest_accuracy_idx = np.argmax(accuracy)\nbest_tpr_idx = np.argmax(TPR)\nbest_fpr_idx = np.argmin(FPR)\n\nbest_accuracy_threshold = thresholds[best_accuracy_idx]\nbest_tpr_threshold = thresholds[best_tpr_idx]\nbest_fpr_threshold = thresholds[best_fpr_idx]\n\n# Plotting\nplt.figure(figsize=(14, 8))\n\n# Accuracy\nplt.plot(thresholds, accuracy, label='Accuracy', marker='o')\nplt.scatter(best_accuracy_threshold, accuracy[best_accuracy_idx], color='red')  # Highlight best accuracy\n\n# True Positive Rate (TPR)\nplt.plot(thresholds, TPR, label='True Positive Rate (TPR)', marker='o')\nplt.scatter(best_tpr_threshold, TPR[best_tpr_idx], color='green')  # Highlight best TPR\n\n# False Positive Rate (FPR)\nplt.plot(thresholds, FPR, label='False Positive Rate (FPR)', marker='o')\nplt.scatter(best_fpr_threshold, FPR[best_fpr_idx], color='blue')  # Highlight best (lowest) FPR\n# True Negative Rate (TNR)\nplt.plot(thresholds, TNR, label='True Negative Rate (TNR)', marker='o')\n\n# Adjusting x-axis scale\nplt.xlim(min(thresholds), max(thresholds))\nplt.xticks(np.linspace(min(thresholds), max(thresholds), num=10))\n\nplt.xlabel('Threshold')\nplt.ylabel('Metric Value')\nplt.title('Classification Metrics vs. Threshold (Global Classifier)')\nplt.legend(loc=(0.76, 0.67))\nplt.grid(True)\n\n# Add vertical dashed lines and annotate the x-axis\nplt.axvline(x=best_accuracy_threshold, color='red', linestyle='--')\nplt.annotate(f'{best_accuracy_threshold:.5f}', xy=(best_accuracy_threshold, 0), xytext=(best_accuracy_threshold, -0.05),\n             arrowprops=dict(facecolor='red', shrink=0.05), horizontalalignment='center')\n\nplt.axvline(x=best_tpr_threshold, color='green', linestyle='--')\nplt.annotate(f'{best_tpr_threshold:.5f}', xy=(best_tpr_threshold, 0), xytext=(best_tpr_threshold, -0.05),\n             arrowprops=dict(facecolor='green', shrink=0.05), horizontalalignment='center')\n\n\"\"\"# Add a text box with the best values\ntextstr = '\\n'.join((\n    f'Best Accuracy: {accuracy[best_accuracy_idx]:.5f} at threshold {best_accuracy_threshold}',\n    f'Best TPR: {TPR[best_tpr_idx]:.5f} at threshold {best_tpr_threshold}',\n))\n\n# Place a text box to the right of the plot\nprops = dict(boxstyle='round', facecolor='white', alpha=0.5)\nplt.gcf().text(0.95, 0.5, textstr, fontsize=12, verticalalignment='center', bbox=props)\n\nplt.show()\"\"\"\nprint(f'\\nBest Accuracy: {accuracy[best_accuracy_idx]:.5f} at threshold {best_accuracy_threshold}',\n    f'\\nBest TPR: {TPR[best_tpr_idx]:.5f} at threshold {best_tpr_threshold}\\n') ","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:34:32.300790Z","iopub.execute_input":"2024-05-26T11:34:32.301246Z","iopub.status.idle":"2024-05-26T11:34:32.879876Z","shell.execute_reply.started":"2024-05-26T11:34:32.301209Z","shell.execute_reply":"2024-05-26T11:34:32.878718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_test = {}\nj=0\nfor data in test_data:\n    for i in client_models:\n        model = client_models[i]\n        model.eval()\n        layer_output = model(torch.Tensor(data))\n        try:\n            compressed_test[i].append(layer_output)\n        except:\n            compressed_test[i] = [layer_output]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:39:11.640025Z","iopub.execute_input":"2024-05-26T11:39:11.640550Z","iopub.status.idle":"2024-05-26T11:42:20.976053Z","shell.execute_reply.started":"2024-05-26T11:39:11.640514Z","shell.execute_reply":"2024-05-26T11:42:20.974864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_accuracy_threshold=0.04250108653979267","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:42:21.117373Z","iopub.execute_input":"2024-05-26T11:42:21.117804Z","iopub.status.idle":"2024-05-26T11:42:21.165497Z","shell.execute_reply.started":"2024-05-26T11:42:21.117776Z","shell.execute_reply":"2024-05-26T11:42:21.164110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_new_data(new_data_point, threshold):\n    # Predict the cluster for the new data point\n    new_data_cluster = kmeans.predict(np.array(new_data_point))\n    # Get the centroid of the predicted cluster\n    centroid = kmeans.cluster_centers_[new_data_cluster]\n    # Calculate the Euclidean distance between the new data point and the centroid\n    distance = np.sqrt(np.sum((new_data_point - centroid) ** 2))\n    # Classify based on the distance'\n    \n    if distance < threshold:\n        return new_data_cluster[0]\n    else:\n        return False\n\nthreshold = best_tpr_threshold\n\n\n\n# Iterate through the compressed_mixed dictionary and classify each data point\nfor model, data_list in compressed_test.items():\n    TP,FP,TN,FN = 0, 0, 0, 0\n    j = 0\n    for data in data_list:\n        # Convert the data to NumPy array and detach from computation graph\n        data_np = data.detach().numpy()\n        data_np = data_np.reshape(1,-1)\n        # Convert the data to double data type before passing it to KMeans model\n        if classify_new_data(data_np, threshold) == False:\n            classification_result = False\n        else: \n            classification_result = cluster_labels[classify_new_data(data_np, threshold)]\n        if classification_result == False:\n            if model == test_data_labels[j]:\n                FN += 1\n            else:\n                TN += 1\n        else:\n            if classification_result == test_data_labels[j]:\n                if model == test_data_labels[j]:\n                    TP += 1\n                else:\n                    FP += 1\n            else:\n                FN += 1\n        j += 1\n            \n\n\n    print()\n    # Calculate accuracy\n    accuracy = (TP + TN) / (TP + TN + FP + FN)\n\n    # Calculate true positive rate (TPR) or sensitivity or recall\n    TPR = TP / (TP + FN)\n\n    # Calculate false positive rate (FPR)\n    FPR = FP / (FP + TN)\n\n    # Calculate specificity or true negative rate (TNR)\n    TNR = TN / (FP + TN)\n\n    # Calculate precision or positive predictive value (PPV)\n    PPV = TP / (TP + FP)\n\n\n\n    # Print the metrics with up to four decimal places\n    print(f\"Data from :\" +str(model))\n    print(\"TP:\", f\"{TP}\")\n    print(\"TN:\", f\"{TN}\")\n    print(\"FP:\", f\"{FP}\")\n    print(\"FN:\", f\"{FN}\")\n    print(\"Accuracy:\", f\"{accuracy*100:.4f}\")\n    print(\"True Positive Rate (TPR):\", f\"{TPR:.4f}\")\n    print(\"False Positive Rate (FPR):\", f\"{FPR:.4f}\")\n    print(\"True Negative Rate (TNR):\", f\"{TNR:.4f}\")\n    print(\"Positive Predictive Value (PPV):\", f\"{PPV:.4f}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:42:21.194411Z","iopub.execute_input":"2024-05-26T11:42:21.194871Z","iopub.status.idle":"2024-05-26T11:44:47.835915Z","shell.execute_reply.started":"2024-05-26T11:42:21.194841Z","shell.execute_reply":"2024-05-26T11:44:47.834695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nthreshold = best_tpr_threshold\nTP,FP,TN,FN = 0,0,0,0\n\n# Iterate through the compressed_mixed dictionary and classify each data point\nfor model, data_list in compressed_test.items():\n    j = 0\n    for data in data_list:\n        # Convert the data to NumPy array and detach from computation graph\n        data_np = data.detach().numpy()\n        data_np = data_np.reshape(1,-1)\n        # Convert the data to double data type before passing it to KMeans model\n        if classify_new_data(data_np, threshold) == False:\n            classification_result = False\n        else: \n            classification_result = cluster_labels[classify_new_data(data_np, threshold)]\n        if classification_result == False:\n            if model == test_data_labels[j]:\n                FN += 1\n            else:\n                TN += 1\n        else:\n            if classification_result == test_data_labels[j]:\n                if model == test_data_labels[j]:\n                    TP += 1\n                else:\n                    FP += 1\n            else:\n                FN += 1\n        j += 1\n            \n\n\nprint()\n# Calculate accuracy\naccuracy = (TP + TN) / (TP + TN + FP + FN)\n\n# Calculate true positive rate (TPR) or sensitivity or recall\nTPR = TP / (TP + FN)\n\n# Calculate false positive rate (FPR)\nFPR = FP / (FP + TN)\n\n# Calculate specificity or true negative rate (TNR)\nTNR = TN / (FP + TN)\n\n# Calculate precision or positive predictive value (PPV)\nPPV = TP / (TP + FP)\n\n\n\n# Print the metrics with up to four decimal places\nprint(f\"Global Classifier :\")\nprint(\"TP:\", f\"{TP}\")\nprint(\"TN:\", f\"{TN}\")\nprint(\"FP:\", f\"{FP}\")\nprint(\"FN:\", f\"{FN}\")\nprint(\"Accuracy:\", f\"{accuracy*100:.4f}\")\nprint(\"True Positive Rate (TPR):\", f\"{TPR:.4f}\")\nprint(\"False Positive Rate (FPR):\", f\"{FPR:.4f}\")\nprint(\"True Negative Rate (TNR):\", f\"{TNR:.4f}\")\nprint(\"Positive Predictive Value (PPV):\", f\"{PPV:.4f}\")\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:44:47.838158Z","iopub.execute_input":"2024-05-26T11:44:47.838570Z","iopub.status.idle":"2024-05-26T11:47:14.479187Z","shell.execute_reply.started":"2024-05-26T11:44:47.838537Z","shell.execute_reply":"2024-05-26T11:47:14.477785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nc=Counter(mixed_data_labels)\nc","metadata":{"execution":{"iopub.status.busy":"2024-05-16T19:58:26.835091Z","iopub.execute_input":"2024-05-16T19:58:26.835564Z","iopub.status.idle":"2024-05-16T19:58:26.850526Z","shell.execute_reply.started":"2024-05-16T19:58:26.835516Z","shell.execute_reply":"2024-05-16T19:58:26.849016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom joblib import dump\n\n# Define the directory path\ndirectory = '/kaggle/working/models_fixed_overfit'\n\n# Create the directory if it does not exist\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\n# Save the kmeans model\ndump(kmeans, '/kaggle/working/models_fixed_overfit/kmeans_model.joblib')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:48:36.456528Z","iopub.execute_input":"2024-05-26T11:48:36.457072Z","iopub.status.idle":"2024-05-26T11:48:36.469735Z","shell.execute_reply.started":"2024-05-26T11:48:36.457036Z","shell.execute_reply":"2024-05-26T11:48:36.468441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding clusters","metadata":{}},{"cell_type":"code","source":"labels_to_remove=[]\nfor i in new:\n    if i[:-2] in old and i[:-2] not in labels_to_remove:\n        labels_to_remove.append(i[:-2])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:58:35.606282Z","iopub.execute_input":"2024-05-26T10:58:35.607396Z","iopub.status.idle":"2024-05-26T10:58:35.612986Z","shell.execute_reply.started":"2024-05-26T10:58:35.607328Z","shell.execute_reply":"2024-05-26T10:58:35.611752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_remove","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:58:36.150836Z","iopub.execute_input":"2024-05-26T10:58:36.151268Z","iopub.status.idle":"2024-05-26T10:58:36.158912Z","shell.execute_reply.started":"2024-05-26T10:58:36.151236Z","shell.execute_reply":"2024-05-26T10:58:36.157638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the encoder-only model class\nclass AEModelEncoder(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModelEncoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        \n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        return x\n\n# Function to load encoder weights from the full model\ndef load_encoder_weights(full_model, encoder_model):\n    encoder_model.fc1.weight.data = full_model.fc1.weight.data\n    encoder_model.fc1.bias.data = full_model.fc1.bias.data\n    encoder_model.fc2.weight.data = full_model.fc2.weight.data\n    encoder_model.fc2.bias.data = full_model.fc2.bias.data\n    encoder_model.fc3.weight.data = full_model.fc3.weight.data\n    encoder_model.fc3.bias.data = full_model.fc3.bias.data\n    encoder_model.fc4.weight.data = full_model.fc4.weight.data\n    encoder_model.fc4.bias.data = full_model.fc4.bias.data\n    encoder_model.fc5.weight.data = full_model.fc5.weight.data\n    encoder_model.fc5.bias.data = full_model.fc5.bias.data\n    encoder_model.fc6.weight.data = full_model.fc6.weight.data\n    encoder_model.fc6.bias.data = full_model.fc6.bias.data\n    encoder_model.fc7.weight.data = full_model.fc7.weight.data\n    encoder_model.fc7.bias.data = full_model.fc7.bias.data\n\n# Update client_models to use the encoder-only model\nextra_clients = {}\nfor device in devices:\n    if device[:-2] in devices or device in labels_to_remove:\n        full_model = torch.load('/kaggle/input/models_fixed_overfit/pytorch/sgd_fed_harlem/1/models_extra/clients/' + device + '.pt')\n        encoder_model = AEModelEncoder(input_dim)\n        load_encoder_weights(full_model, encoder_model)\n        extra_clients[device] = encoder_model\nextra_clients.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:58:37.998393Z","iopub.execute_input":"2024-05-26T10:58:37.999105Z","iopub.status.idle":"2024-05-26T10:58:38.151461Z","shell.execute_reply.started":"2024-05-26T10:58:37.999073Z","shell.execute_reply":"2024-05-26T10:58:38.150364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra_compressed_outs = {}\nextra_compressed_outs_test = {}\nfor i in extra_clients:\n    model = extra_clients[i]\n    model.eval()\n    dataloader = train_loader[i]\n    outs = []\n    ind = 0\n    flag = False\n    for batch in dataloader:\n        for data in batch:\n            layer_output = model(data.float()).detach().numpy()\n            outs.append(layer_output)\n            ind += 1\n            if ind == 10000:\n                extra_compressed_outs[i] = outs\n                outs = []\n            elif ind == 10010:\n                extra_compressed_outs_test[i] = outs\n                flag = True\n                break\n        if flag:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:58:49.090956Z","iopub.execute_input":"2024-05-26T10:58:49.091421Z","iopub.status.idle":"2024-05-26T10:59:19.342932Z","shell.execute_reply.started":"2024-05-26T10:58:49.091384Z","shell.execute_reply":"2024-05-26T10:59:19.341638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in extra_compressed_outs:\n    if i[:-2] in extra_compressed_outs:\n        for j in extra_compressed_outs[i]:\n            extra_compressed_outs[i[:-2]].append(j)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.345212Z","iopub.execute_input":"2024-05-26T10:59:19.345711Z","iopub.status.idle":"2024-05-26T10:59:19.367758Z","shell.execute_reply.started":"2024-05-26T10:59:19.345670Z","shell.execute_reply":"2024-05-26T10:59:19.366461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[]\nfor i in extra_compressed_outs:\n    if i[-2]==\"-\":\n        l.append(i)\nfor i in l:\n    extra_compressed_outs.pop(i)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.369192Z","iopub.execute_input":"2024-05-26T10:59:19.369572Z","iopub.status.idle":"2024-05-26T10:59:19.384765Z","shell.execute_reply.started":"2024-05-26T10:59:19.369543Z","shell.execute_reply":"2024-05-26T10:59:19.383420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in extra_compressed_outs.keys():\n    print(i,': ',len(extra_compressed_outs[i]))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.387170Z","iopub.execute_input":"2024-05-26T10:59:19.387528Z","iopub.status.idle":"2024-05-26T10:59:19.396974Z","shell.execute_reply.started":"2024-05-26T10:59:19.387498Z","shell.execute_reply":"2024-05-26T10:59:19.395901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n# Extract data from the dictionary\ndata_new = []\nlabels_new = []\n\nfor label, tensors in extra_compressed_outs.items():\n    for tensor in tensors:\n        data_new.append(tensor)\n        labels_new.append(label)\n\ndata_new = np.array(data_new)\nlabels_new = np.array(labels_new)\n\n# Get the number of samples\nnum_samples = len(data_new)\n\n# Generate a random permutation of indices\npermutation_indices = np.random.permutation(num_samples)\n\n# Shuffle data and labels arrays using the permutation\nshuffled_data = data_new[permutation_indices]\nshuffled_labels = labels_new[permutation_indices]\ndata_new=shuffled_data\nlabels_new=shuffled_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.398413Z","iopub.execute_input":"2024-05-26T10:59:19.400283Z","iopub.status.idle":"2024-05-26T10:59:19.537025Z","shell.execute_reply.started":"2024-05-26T10:59:19.400249Z","shell.execute_reply":"2024-05-26T10:59:19.535825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# Assuming you have the trained KMeans model stored as kmeans_model\n# Assuming you have the cluster labels stored in cluster_labels dictionary\n# Assuming you have the labels you want to remove stored in labels_to_remove list\n\ncentroids_to_keep = []\nlabels_to_keep = []\n\n# Iterate over the cluster labels\nfor cluster, label in cluster_labels.items():\n    # Check if the label is not in labels_to_remove\n    if label not in labels_to_remove:\n        # Append the cluster centroid and label for clusters to keep\n        centroids_to_keep.append(kmeans.cluster_centers_[cluster])\n        labels_to_keep.append(label)\n\n# Convert the lists to numpy arrays\ncentroids_to_keep = np.array(centroids_to_keep)\nlabels_to_keep = np.array(labels_to_keep)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.538516Z","iopub.execute_input":"2024-05-26T10:59:19.538954Z","iopub.status.idle":"2024-05-26T10:59:19.545634Z","shell.execute_reply.started":"2024-05-26T10:59:19.538917Z","shell.execute_reply":"2024-05-26T10:59:19.544405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(centroids_to_keep))\nprint(n)\nprint(n-len(centroids_to_keep))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.547213Z","iopub.execute_input":"2024-05-26T10:59:19.547877Z","iopub.status.idle":"2024-05-26T10:59:19.557965Z","shell.execute_reply.started":"2024-05-26T10:59:19.547836Z","shell.execute_reply":"2024-05-26T10:59:19.556617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_keep","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.559405Z","iopub.execute_input":"2024-05-26T10:59:19.559749Z","iopub.status.idle":"2024-05-26T10:59:19.571293Z","shell.execute_reply.started":"2024-05-26T10:59:19.559720Z","shell.execute_reply":"2024-05-26T10:59:19.570123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store the previous centroids\nprevious_centroids = centroids_to_keep\n\n# Calculate the total number of clusters for the new model\nnew_n_clusters = n-len(centroids_to_keep)\n\n# Create a new KMeans model with the desired number of clusters\nnew_kmeans = KMeans(n_clusters=new_n_clusters, random_state=100)\nnew_kmeans.fit(data_new)\n# Initialize the centroids of the new model with the previous centroids\nnew_kmeans.cluster_centers_ = np.vstack((previous_centroids, new_kmeans.cluster_centers_))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:19.572942Z","iopub.execute_input":"2024-05-26T10:59:19.573934Z","iopub.status.idle":"2024-05-26T10:59:21.084392Z","shell.execute_reply.started":"2024-05-26T10:59:19.573894Z","shell.execute_reply":"2024-05-26T10:59:21.083190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels = new_kmeans.predict(data_new)\n# Dictionary to store attacks and their counts for each cluster\ncluster_attacks_count = {cluster: {} for cluster in range(len(new_kmeans.cluster_centers_))}\n\n# Iterate through data and cluster labels\nfor idx, cluster_label in enumerate(cluster_labels):\n    attack = labels_new[idx]\n    if attack not in cluster_attacks_count[cluster_label]:\n        cluster_attacks_count[cluster_label][attack] = 1\n        \n    else:\n        cluster_attacks_count[cluster_label][attack] += 1\n# Print attacks and their counts for each cluster\nfor cluster, attack_counts in cluster_attacks_count.items():\n    print(f\"Cluster {cluster}: {attack_counts}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:21.087807Z","iopub.execute_input":"2024-05-26T10:59:21.088264Z","iopub.status.idle":"2024-05-26T10:59:21.467402Z","shell.execute_reply.started":"2024-05-26T10:59:21.088226Z","shell.execute_reply":"2024-05-26T10:59:21.466109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cluster, attack_counts in cluster_attacks_count.items():\n    if cluster<len(labels_to_keep):\n        cluster_attacks_count[cluster]={labels_to_keep[cluster] : 1}\ncluster_attacks_count","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:21.468661Z","iopub.execute_input":"2024-05-26T10:59:21.468997Z","iopub.status.idle":"2024-05-26T10:59:21.478088Z","shell.execute_reply.started":"2024-05-26T10:59:21.468971Z","shell.execute_reply":"2024-05-26T10:59:21.476944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the encoder-only model class\nclass AEModelEncoder(nn.Module):\n    def __init__(self, input_dim):\n        super(AEModelEncoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.fc2 = nn.Linear(input_dim, 64)  \n        self.fc3 = nn.Linear(64, 48)\n        self.fc4 = nn.Linear(48, 32)\n        self.fc5 = nn.Linear(32, 24)\n        self.fc6 = nn.Linear(24, 16)\n        self.fc7 = nn.Linear(16, 16)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)  # Dropout layer with probability 0.2\n        \n        # Initialize weights\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n        \n    def forward(self, x):\n        x = self.fc1(x) \n        x = self.activation(x)\n        x = self.dropout(x)  # Apply dropout\n        x = self.fc2(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc4(x) \n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc5(x)\n        x = self.activation(x) \n        x = self.dropout(x)\n        x = self.fc6(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc7(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        return x\n\n# Function to load encoder weights from the full model\ndef load_encoder_weights(full_model, encoder_model):\n    encoder_model.fc1.weight.data = full_model.fc1.weight.data\n    encoder_model.fc1.bias.data = full_model.fc1.bias.data\n    encoder_model.fc2.weight.data = full_model.fc2.weight.data\n    encoder_model.fc2.bias.data = full_model.fc2.bias.data\n    encoder_model.fc3.weight.data = full_model.fc3.weight.data\n    encoder_model.fc3.bias.data = full_model.fc3.bias.data\n    encoder_model.fc4.weight.data = full_model.fc4.weight.data\n    encoder_model.fc4.bias.data = full_model.fc4.bias.data\n    encoder_model.fc5.weight.data = full_model.fc5.weight.data\n    encoder_model.fc5.bias.data = full_model.fc5.bias.data\n    encoder_model.fc6.weight.data = full_model.fc6.weight.data\n    encoder_model.fc6.bias.data = full_model.fc6.bias.data\n    encoder_model.fc7.weight.data = full_model.fc7.weight.data\n    encoder_model.fc7.bias.data = full_model.fc7.bias.data\n\n# Update client_models to use the encoder-only model\nclient_models = {}\nfor device in devices:\n    full_model = torch.load('/kaggle/input/models_fixed_overfit/pytorch/sgd_fed_harlem/1/models_extra/clients/' + device + '.pt')\n    encoder_model = AEModelEncoder(input_dim)\n    load_encoder_weights(full_model, encoder_model)\n    client_models[device] = encoder_model\nclient_models.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:21.479776Z","iopub.execute_input":"2024-05-26T10:59:21.480144Z","iopub.status.idle":"2024-05-26T10:59:21.577082Z","shell.execute_reply.started":"2024-05-26T10:59:21.480115Z","shell.execute_reply":"2024-05-26T10:59:21.575950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"compressed_outs = {}\ncompressed_outs_test = {}\nfor i in client_models:\n    model = client_models[i]\n    model.eval()\n    dataloader = train_loader[i]\n    outs = []\n    ind = 0\n    flag = False\n    for batch in dataloader:\n        for data in batch:\n            layer_output = model(data.float()).detach().numpy()\n            outs.append(layer_output)\n            ind += 1\n            if ind == 10000:\n                compressed_outs[i] = outs\n                outs = []\n            elif ind == 10010:\n                compressed_outs_test[i] = outs\n                flag = True\n                break\n        if flag:\n            break\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"for i in compressed_outs:\n    if i[:-2] in compressed_outs:\n        for j in compressed_outs[i]:\n            compressed_outs[i[:-2]].append(j)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T09:31:49.253257Z","iopub.status.idle":"2024-05-25T09:31:49.254437Z","shell.execute_reply.started":"2024-05-25T09:31:49.254122Z","shell.execute_reply":"2024-05-25T09:31:49.254149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"l=[]\nfor i in compressed_outs:\n    if i[-2]==\"-\":\n        l.append(i)\nfor i in l:\n    compressed_outs.pop(i)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:24:01.328266Z","iopub.execute_input":"2024-05-22T13:24:01.328790Z","iopub.status.idle":"2024-05-22T13:24:01.341886Z","shell.execute_reply.started":"2024-05-22T13:24:01.328724Z","shell.execute_reply":"2024-05-22T13:24:01.340402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"for i in compressed_outs.keys():\n    print(i,': ',len(compressed_outs[i]))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:24:01.345134Z","iopub.execute_input":"2024-05-22T13:24:01.345601Z","iopub.status.idle":"2024-05-22T13:24:01.354719Z","shell.execute_reply.started":"2024-05-22T13:24:01.345557Z","shell.execute_reply":"2024-05-22T13:24:01.353093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n# Extract data from the dictionary\ndata = []\nlabels = []\n\nfor label, tensors in compressed_outs.items():\n    for tensor in tensors:\n        data.append(tensor)\n        labels.append(label)\n\ndata = np.array(data)\nlabels = np.array(labels)\n\n# Get the number of samples\nnum_samples = len(data)\n\n# Generate a random permutation of indices\npermutation_indices = np.random.permutation(num_samples)\n\n# Shuffle data and labels arrays using the permutation\nshuffled_data = data[permutation_indices]\nshuffled_labels = labels[permutation_indices]\ndata=shuffled_data\nlabels=shuffled_labels\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:24:01.356301Z","iopub.execute_input":"2024-05-22T13:24:01.356757Z","iopub.status.idle":"2024-05-22T13:24:01.577855Z","shell.execute_reply.started":"2024-05-22T13:24:01.356716Z","shell.execute_reply":"2024-05-22T13:24:01.576849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"cluster_labels = new_kmeans.predict(data)\n\n# Get the cluster centroids\ncentroids = new_kmeans.cluster_centers_\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:24:01.579357Z","iopub.execute_input":"2024-05-22T13:24:01.579790Z","iopub.status.idle":"2024-05-22T13:24:01.592806Z","shell.execute_reply.started":"2024-05-22T13:24:01.579751Z","shell.execute_reply":"2024-05-22T13:24:01.591709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Dictionary to store attacks and their counts for each cluster\nn=len(centroids)\ncluster_attacks_count = {cluster: {} for cluster in range(n)}\n\n# Iterate through data and cluster labels\nfor idx, cluster_label in enumerate(cluster_labels):\n    attack = labels[idx]\n    if attack not in cluster_attacks_count[cluster_label]:\n        cluster_attacks_count[cluster_label][attack] = 1\n        \n    else:\n        cluster_attacks_count[cluster_label][attack] += 1\n    \n# Print attacks and their counts for each cluster\nfor cluster, attack_counts in cluster_attacks_count.items():\n    print(f\"Cluster {cluster}: {attack_counts}\")\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:24:23.961228Z","iopub.execute_input":"2024-05-22T13:24:23.962179Z","iopub.status.idle":"2024-05-22T13:24:24.958429Z","shell.execute_reply.started":"2024-05-22T13:24:23.962139Z","shell.execute_reply":"2024-05-22T13:24:24.957251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels = {}\nfor i in range(len(cluster_attacks_count)):\n    cluster_labels[i] = max(cluster_attacks_count[i], key=cluster_attacks_count[i].get)\ncluster_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:31.909981Z","iopub.execute_input":"2024-05-26T10:59:31.910426Z","iopub.status.idle":"2024-05-26T10:59:31.918920Z","shell.execute_reply.started":"2024-05-26T10:59:31.910392Z","shell.execute_reply":"2024-05-26T10:59:31.917717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_labels={0: 'DoS attacks-Hulk',\n 1: 'DoS attacks-SlowHTTPTest',\n 2: 'DDoS attacks-LOIC-HTTP',\n 3: 'DDoS attacks-LOIC-HTTP',\n 4: 'DoS attacks-Hulk',\n 5: 'DoS attacks-SlowHTTPTest',\n 6: 'DoS attacks-Hulk',\n 7: 'DoS attacks-SlowHTTPTest',\n 8: 'DoS attacks-SlowHTTPTest',\n 9: 'DDoS attacks-LOIC-HTTP',\n 10: 'DoS attacks-SlowHTTPTest',\n 11: 'DDoS attacks-LOIC-HTTP',\n 12: 'FTP-BruteForce',\n 13: 'DDOS attack-HOIC',\n 14: 'DDOS attack-HOIC',\n 15: 'FTP-BruteForce',\n 16: 'SSH-Bruteforce',\n 17: 'SSH-Bruteforce',\n 18: 'Bot',\n 19: 'Bot',\n 20: 'FTP-BruteForce',\n 21: 'FTP-BruteForce'}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:43.652436Z","iopub.execute_input":"2024-05-26T10:59:43.652865Z","iopub.status.idle":"2024-05-26T10:59:43.659229Z","shell.execute_reply.started":"2024-05-26T10:59:43.652835Z","shell.execute_reply":"2024-05-26T10:59:43.658038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[]\nfor i in client_models.keys():\n    if i[-2]==\"-\":\n        l.append(i)\nfor i in l:\n    client_models.pop(i)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:45.051781Z","iopub.execute_input":"2024-05-26T10:59:45.052206Z","iopub.status.idle":"2024-05-26T10:59:45.059302Z","shell.execute_reply.started":"2024-05-26T10:59:45.052173Z","shell.execute_reply":"2024-05-26T10:59:45.058010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_mixed = {}\nj=0\nfor data in mixed_data:\n    if j<1000:\n        for i in client_models:\n            model = client_models[i]\n            model.eval()\n            layer_output = model(torch.Tensor(data))\n            try:\n                compressed_mixed[i].append(layer_output)\n            except:\n                compressed_mixed[i] = [layer_output]\n    j+=1","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:59:52.815477Z","iopub.execute_input":"2024-05-26T10:59:52.815908Z","iopub.status.idle":"2024-05-26T10:59:56.002261Z","shell.execute_reply.started":"2024-05-26T10:59:52.815876Z","shell.execute_reply":"2024-05-26T10:59:56.000728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_thresholds={'Bot': 0.31418854651204847,\n 'DDOS attack-HOIC': 0.03866640203996175,\n 'DDoS attacks-LOIC-HTTP': 0.46889474594200486,\n 'DoS attacks-Hulk': 0.48591240802465874,\n 'DoS attacks-SlowHTTPTest': 0.1051760870436359,\n 'FTP-BruteForce': 0.04449623069596497,\n 'SSH-Bruteforce': 0.07784218174722095}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:00:06.106151Z","iopub.execute_input":"2024-05-26T11:00:06.107251Z","iopub.status.idle":"2024-05-26T11:00:06.112619Z","shell.execute_reply.started":"2024-05-26T11:00:06.107210Z","shell.execute_reply":"2024-05-26T11:00:06.111278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_new_data_fed(new_data_point, threshold):\n    # Predict the cluster for the new data point\n    new_data_cluster = new_kmeans.predict(np.array(new_data_point))\n    # Get the centroid of the predicted cluster\n    centroid = new_kmeans.cluster_centers_[new_data_cluster]\n    # Calculate the Euclidean distance between the new data point and the centroid\n    distance = np.sqrt(np.sum((new_data_point - centroid) ** 2))\n    # Classify based on the distance\n    if distance < threshold:\n        return new_data_cluster[0]\n    else:\n        return False\n\n\nnum_encoders=7\nnum_clusters=22\nnum_clients=12\nfed_met=[]\nstart = 0\nend =  min(old_thresholds.values())*num_encoders\nstep = end/num_clusters\ni = start\nfirst_fed_round=[]\nprev_TPR=0\n\nfor x in range(num_clients):\n    fed_met=[]\n    print(\"Round :\"+str(x+1))\n    while i < end:\n        TP,FP,TN,FN = 0,0,0,0\n        # Iterate through the compressed_mixed dictionary and classify each data point\n        for model, data_list in compressed_mixed.items():\n            j = 0\n            for data in data_list:\n                # Convert the data to NumPy array and detach from computation graph\n                data_np = data.detach().numpy()\n                data_np = data_np.reshape(1,-1)\n                # Convert the data to double data type before passing it to KMeans model\n                if classify_new_data_fed(data_np, i) == False:\n                    classification_result = False\n                else: \n                    classification_result = cluster_labels[classify_new_data_fed(data_np, i)]\n                if classification_result == False:\n                    if model == mixed_data_labels[j]:\n                        FN += 1\n                    else:\n                        TN += 1\n                else:\n                    if classification_result == mixed_data_labels[j]:\n                        if model == mixed_data_labels[j]:\n                            TP += 1\n                        else:\n                            FP += 1\n                    else:\n                        FN += 1\n                j += 1\n\n        if TP==0:\n            TP=0.1\n\n        #print(i)\n        # Calculate accuracy\n        accuracy = (TP + TN) / (TP + TN + FP + FN)\n\n        # Calculate true positive rate (TPR) or sensitivity or recall\n        TPR = TP / (TP + FN)\n\n        # Calculate false positive rate (FPR)\n        FPR = FP / (FP + TN)\n\n        # Calculate specificity or true negative rate (TNR)\n        TNR = TN / (FP + TN)\n\n        # Calculate precision or positive predictive value (PPV)\n        PPV = TP / (TP + FP)\n\n        fed_met.append([i,accuracy,TPR,FPR,TNR])\n        if x==0:\n            first_fed_round.append([i,accuracy,TPR,FPR,TNR])\n        i += step\n    print(fed_met)\n    # Extracting data from 'fed_met' list\n    thresholds = [entry[0] for entry in fed_met]\n    TPR = [entry[2] for entry in fed_met]\n\n    # Find the best thresholds\n    # best_accuracy_idx = np.argmax(accuracy)\n\n    best_tpr_idx = np.argmax(TPR)\n    best_TPR = round(TPR[best_tpr_idx], 4)\n    if best_tpr_idx==0:\n        start=thresholds[best_tpr_idx]\n    else:\n        start=thresholds[best_tpr_idx-1]\n    if best_tpr_idx == len(thresholds) - 1:\n        end = thresholds[best_tpr_idx]\n    else:\n        end = thresholds[best_tpr_idx + 1]\n    step = end/num_clusters\n    i=start\n    if prev_TPR==best_TPR:\n        break\n    prev_TPR=best_TPR\n    #nxt_acc_thresh = thresholds[best_accuracy_idx+1]\n    #nxt_tpr_thresh = thresholds[best_tpr_idx+1]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:01:35.692514Z","iopub.execute_input":"2024-05-26T11:01:35.692981Z","iopub.status.idle":"2024-05-26T11:03:42.391924Z","shell.execute_reply.started":"2024-05-26T11:01:35.692949Z","shell.execute_reply":"2024-05-26T11:03:42.390701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting data from 'fed_met' list\nthresholds = [entry[0] for entry in fed_met]\naccuracy = [entry[1] for entry in fed_met]\nTPR = [entry[2] for entry in fed_met]\nFPR = [entry[3] for entry in fed_met]\nTNR = [entry[4] for entry in fed_met]\n\n# Find the best thresholds\nbest_accuracy_idx = np.argmax(accuracy)\nbest_tpr_idx = np.argmax(TPR)\nbest_fpr_idx = np.argmin(FPR)\n\nbest_accuracy_threshold = thresholds[best_accuracy_idx]\nbest_tpr_threshold = thresholds[best_tpr_idx]\nbest_tpr_threshold","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:03:51.015585Z","iopub.execute_input":"2024-05-26T11:03:51.015983Z","iopub.status.idle":"2024-05-26T11:03:51.026053Z","shell.execute_reply.started":"2024-05-26T11:03:51.015956Z","shell.execute_reply":"2024-05-26T11:03:51.024752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting data from 'fed_met' list\nthresholds = [entry[0] for entry in first_fed_round]\naccuracy = [entry[1] for entry in first_fed_round]\nTPR = [entry[2] for entry in first_fed_round]\nFPR = [entry[3] for entry in first_fed_round]\nTNR = [entry[4] for entry in first_fed_round]\n\n# Find the best thresholds\nbest_accuracy_idx = np.argmax(accuracy)\nbest_tpr_idx = np.argmax(TPR)\nbest_fpr_idx = np.argmin(FPR)\n\nbest_accuracy_threshold = thresholds[best_accuracy_idx]\nbest_tpr_threshold = thresholds[best_tpr_idx]\n\n# Plotting\nplt.figure(figsize=(14, 8))\n\n# Accuracy\nplt.plot(thresholds, accuracy, label='Accuracy', marker='o')\nplt.scatter(best_accuracy_threshold, accuracy[best_accuracy_idx], color='red')  # Highlight best accuracy\n\n# True Positive Rate (TPR)\nplt.plot(thresholds, TPR, label='True Positive Rate (TPR)', marker='o')\nplt.scatter(best_tpr_threshold, TPR[best_tpr_idx], color='green')  # Highlight best TPR\n\n# False Positive Rate (FPR)\nplt.plot(thresholds, FPR, label='False Positive Rate (FPR)', marker='o')\nplt.scatter(best_fpr_threshold, FPR[best_fpr_idx], color='blue')  # Highlight best (lowest) FPR\n# True Negative Rate (TNR)\nplt.plot(thresholds, TNR, label='True Negative Rate (TNR)', marker='o')\n\n# Adjusting x-axis scale\nplt.xlim(min(thresholds), max(thresholds))\nplt.xticks(np.linspace(min(thresholds), max(thresholds), num=10))\n\nplt.xlabel('Threshold')\nplt.ylabel('Metric Value')\nplt.title('Classification Metrics vs. Threshold (Global Classifier)')\nplt.legend(loc=(0.75, 0.6))\nplt.grid(True)\n\n# Add vertical dashed lines and annotate the x-axis\nplt.axvline(x=best_accuracy_threshold, color='red', linestyle='--')\nplt.annotate(f'{best_accuracy_threshold:.5f}', xy=(best_accuracy_threshold, 0), xytext=(best_accuracy_threshold, -0.05),\n             arrowprops=dict(facecolor='red', shrink=0.05), horizontalalignment='center')\n\nplt.axvline(x=best_tpr_threshold, color='green', linestyle='--')\nplt.annotate(f'{best_tpr_threshold:.5f}', xy=(best_tpr_threshold, 0), xytext=(best_tpr_threshold, -0.05),\n             arrowprops=dict(facecolor='green', shrink=0.05), horizontalalignment='center')\n\n\"\"\"# Add a text box with the best values\ntextstr = '\\n'.join((\n    f'Best Accuracy: {accuracy[best_accuracy_idx]:.5f} at threshold {best_accuracy_threshold}',\n    f'Best TPR: {TPR[best_tpr_idx]:.5f} at threshold {best_tpr_threshold}',\n))\n\n# Place a text box to the right of the plot\nprops = dict(boxstyle='round', facecolor='white', alpha=0.5)\nplt.gcf().text(0.95, 0.5, textstr, fontsize=12, verticalalignment='center', bbox=props)\n\nplt.show()\"\"\"\nprint(f'\\nBest Accuracy: {accuracy[best_accuracy_idx]:.5f} at threshold {best_accuracy_threshold}',\n    f'\\nBest TPR: {TPR[best_tpr_idx]:.5f} at threshold {best_tpr_threshold}\\n') ","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:03:52.422773Z","iopub.execute_input":"2024-05-26T11:03:52.423608Z","iopub.status.idle":"2024-05-26T11:03:52.957688Z","shell.execute_reply.started":"2024-05-26T11:03:52.423569Z","shell.execute_reply":"2024-05-26T11:03:52.956627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_test = {}\nfor data in test_data:\n    for i in client_models:\n        model = client_models[i]\n        model.eval()\n        layer_output = model(torch.Tensor(data))\n        try:\n            compressed_test[i].append(layer_output)\n        except:\n            compressed_test[i] = [layer_output]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:05:38.269698Z","iopub.execute_input":"2024-05-26T11:05:38.270165Z","iopub.status.idle":"2024-05-26T11:09:10.953694Z","shell.execute_reply.started":"2024-05-26T11:05:38.270132Z","shell.execute_reply":"2024-05-26T11:09:10.952432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_tpr_threshold = 0.016031181615218663","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:15:30.193037Z","iopub.execute_input":"2024-05-26T11:15:30.193546Z","iopub.status.idle":"2024-05-26T11:15:30.199532Z","shell.execute_reply.started":"2024-05-26T11:15:30.193512Z","shell.execute_reply":"2024-05-26T11:15:30.198439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_new_data_fed(new_data_point, threshold):\n    # Predict the cluster for the new data point\n    new_data_cluster = new_kmeans.predict(np.array(new_data_point))\n    # Get the centroid of the predicted cluster\n    centroid = new_kmeans.cluster_centers_[new_data_cluster]\n    # Calculate the Euclidean distance between the new data point and the centroid\n    distance = np.sqrt(np.sum((new_data_point - centroid) ** 2))\n    # Classify based on the distance\n    if distance < threshold:\n        return new_data_cluster[0]\n    else:\n        return False\n\nthreshold = best_tpr_threshold\n\n\n# Iterate through the compressed_mixed dictionary and classify each data point\nfor model, data_list in compressed_test.items():\n    TP,FP,TN,FN = 0, 0, 0, 0\n    j = 0\n    for data in data_list:\n        # Convert the data to NumPy array and detach from computation graph\n        data_np = data.detach().numpy()\n        data_np = data_np.reshape(1,-1)\n        # Convert the data to double data type before passing it to KMeans model\n        if classify_new_data_fed(data_np, threshold) == False:\n            classification_result = False\n        else: \n            classification_result = cluster_labels[classify_new_data_fed(data_np, threshold)]\n        if classification_result == False:\n            if model == test_data_labels[j]:\n                FN += 1\n            else:\n                TN += 1\n        else:\n            if classification_result == test_data_labels[j]:\n                if model == test_data_labels[j]:\n                    TP += 1\n                else:\n                    FP += 1\n            else:\n                FN += 1\n        j += 1\n            \n\n\n    print()\n    # Calculate accuracy\n    accuracy = (TP + TN) / (TP + TN + FP + FN)\n\n    # Calculate true positive rate (TPR) or sensitivity or recall\n    TPR = TP / (TP + FN)\n\n    # Calculate false positive rate (FPR)\n    FPR = FP / (FP + TN)\n\n    # Calculate specificity or true negative rate (TNR)\n    TNR = TN / (FP + TN)\n\n    # Calculate precision or positive predictive value (PPV)\n    PPV = TP / (TP + FP)\n\n\n\n    # Print the metrics with up to four decimal places\n    print(f\"Data from :\" +str(model))\n    print(\"TP:\", f\"{TP}\")\n    print(\"TN:\", f\"{TN}\")\n    print(\"FP:\", f\"{FP}\")\n    print(\"FN:\", f\"{FN}\")\n    print(\"Accuracy:\", f\"{accuracy*100:.4f}\")\n    print(\"True Positive Rate (TPR):\", f\"{TPR:.4f}\")\n    print(\"False Positive Rate (FPR):\", f\"{FPR:.4f}\")\n    print(\"True Negative Rate (TNR):\", f\"{TNR:.4f}\")\n    print(\"Positive Predictive Value (PPV):\", f\"{PPV:.4f}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:15:35.630735Z","iopub.execute_input":"2024-05-26T11:15:35.631121Z","iopub.status.idle":"2024-05-26T11:18:04.686482Z","shell.execute_reply.started":"2024-05-26T11:15:35.631094Z","shell.execute_reply":"2024-05-26T11:18:04.685170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = best_tpr_threshold\nTP,FP,TN,FN = 0,0,0,0\n\n# Iterate through the compressed_mixed dictionary and classify each data point\nfor model, data_list in compressed_test.items():\n    j = 0\n    for data in data_list:\n        # Convert the data to NumPy array and detach from computation graph\n        data_np = data.detach().numpy()\n        data_np = data_np.reshape(1,-1)\n        # Convert the data to double data type before passing it to KMeans model\n        if classify_new_data_fed(data_np, threshold) == False:\n            classification_result = False\n        else: \n            classification_result = cluster_labels[classify_new_data_fed(data_np, threshold)]\n        if classification_result == False:\n            if model == test_data_labels[j]:\n                FN += 1\n            else:\n                TN += 1\n        else:\n            if classification_result == test_data_labels[j]:\n                if model == test_data_labels[j]:\n                    TP += 1\n                else:\n                    FP += 1\n            else:\n                FN += 1\n        j += 1\n            \n\n\nprint()\n# Calculate accuracy\naccuracy = (TP + TN) / (TP + TN + FP + FN)\n\n# Calculate true positive rate (TPR) or sensitivity or recall\nTPR = TP / (TP + FN)\n\n# Calculate false positive rate (FPR)\nFPR = FP / (FP + TN)\n\n# Calculate specificity or true negative rate (TNR)\nTNR = TN / (FP + TN)\n\n# Calculate precision or positive predictive value (PPV)\nPPV = TP / (TP + FP)\n\n\n\n# Print the metrics with up to four decimal places\nprint(f\"Global Classifier :\")\nprint(\"TP:\", f\"{TP}\")\nprint(\"TN:\", f\"{TN}\")\nprint(\"FP:\", f\"{FP}\")\nprint(\"FN:\", f\"{FN}\")\nprint(\"Accuracy:\", f\"{accuracy*100:.4f}\")\nprint(\"True Positive Rate (TPR):\", f\"{TPR:.4f}\")\nprint(\"False Positive Rate (FPR):\", f\"{FPR:.4f}\")\nprint(\"True Negative Rate (TNR):\", f\"{TNR:.4f}\")\nprint(\"Positive Predictive Value (PPV):\", f\"{PPV:.4f}\")\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:18:04.688512Z","iopub.execute_input":"2024-05-26T11:18:04.688865Z","iopub.status.idle":"2024-05-26T11:20:32.555293Z","shell.execute_reply.started":"2024-05-26T11:18:04.688836Z","shell.execute_reply":"2024-05-26T11:20:32.553947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dump(new_kmeans, '/kaggle/working/models_fixed_overfit/fed_kmeans_model.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:48:42.626131Z","iopub.execute_input":"2024-05-26T11:48:42.627407Z","iopub.status.idle":"2024-05-26T11:48:42.638066Z","shell.execute_reply.started":"2024-05-26T11:48:42.627318Z","shell.execute_reply":"2024-05-26T11:48:42.636927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}